{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pair': 'BTC_ETH',\n",
       " 'period': 300,\n",
       " 'input_size': 120,\n",
       " 'output_size': 10,\n",
       " 'lstm_hidden_size': 300,\n",
       " 'columns': ['Close', 'Volume', 'Low', 'High'],\n",
       " 'csv_src_file': 'BTC_ETH',\n",
       " 'name': 'lstm',\n",
       " 'folder': {'data': 'data/', 'weights': 'weights/'},\n",
       " 'filename': 'BTC_ETH_lstm_i120_o10_Close_Volume_Low_High'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import CONFIG\n",
    "from utils import series_to_supervised\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269507</th>\n",
       "      <td>0.082828</td>\n",
       "      <td>1519862700</td>\n",
       "      <td>0.082856</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>4.151247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269508</th>\n",
       "      <td>0.082609</td>\n",
       "      <td>1519863000</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.082606</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>5.551513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269509</th>\n",
       "      <td>0.082552</td>\n",
       "      <td>1519863300</td>\n",
       "      <td>0.082673</td>\n",
       "      <td>0.082547</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>2.327443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269510</th>\n",
       "      <td>0.082460</td>\n",
       "      <td>1519863600</td>\n",
       "      <td>0.082625</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.082552</td>\n",
       "      <td>1.519736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269511</th>\n",
       "      <td>0.082455</td>\n",
       "      <td>1519863900</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.082455</td>\n",
       "      <td>0.552411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close   Timestamp      High       Low      Open    Volume\n",
       "269507  0.082828  1519862700  0.082856  0.082729  0.082729  4.151247\n",
       "269508  0.082609  1519863000  0.082828  0.082606  0.082828  5.551513\n",
       "269509  0.082552  1519863300  0.082673  0.082547  0.082609  2.327443\n",
       "269510  0.082460  1519863600  0.082625  0.082419  0.082552  1.519736\n",
       "269511  0.082455  1519863900  0.082460  0.082418  0.082455  0.552411"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from matplotlib import pyplot\n",
    " \n",
    "#data file path\n",
    "dfp = ''.join([CONFIG['folder']['data'], CONFIG['csv_src_file'], '.csv'])\n",
    "\n",
    "#Columns of price data to use\n",
    "columns = CONFIG['columns']\n",
    "# df = pd.read_csv(dfp).dropna().tail(1000000)\n",
    "dataset = pd.read_csv(dfp)\n",
    "\n",
    "# to drop values before 2018 1514764800, March 2018 1519862400, July 2017 1498867200\n",
    "dataset = dataset[dataset.Timestamp > 1519862400]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.loc[:,columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters to prepare the dataset for learning \n",
    "n_lag = CONFIG['input_size']\n",
    "n_out = CONFIG['output_size']\n",
    "n_features = len(columns)\n",
    "n_lag,n_features,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scale dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-120)</th>\n",
       "      <th>var2(t-120)</th>\n",
       "      <th>var3(t-120)</th>\n",
       "      <th>var4(t-120)</th>\n",
       "      <th>var1(t-119)</th>\n",
       "      <th>var2(t-119)</th>\n",
       "      <th>var3(t-119)</th>\n",
       "      <th>var4(t-119)</th>\n",
       "      <th>var1(t-118)</th>\n",
       "      <th>var2(t-118)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t+7)</th>\n",
       "      <th>var4(t+7)</th>\n",
       "      <th>var1(t+8)</th>\n",
       "      <th>var2(t+8)</th>\n",
       "      <th>var3(t+8)</th>\n",
       "      <th>var4(t+8)</th>\n",
       "      <th>var1(t+9)</th>\n",
       "      <th>var2(t+9)</th>\n",
       "      <th>var3(t+9)</th>\n",
       "      <th>var4(t+9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.911499</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.909966</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867957</td>\n",
       "      <td>0.846472</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.869497</td>\n",
       "      <td>0.846472</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.846470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869497</td>\n",
       "      <td>0.846472</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.846470</td>\n",
       "      <td>0.867833</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.845700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.846470</td>\n",
       "      <td>0.867833</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.859010</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869477</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.859010</td>\n",
       "      <td>0.844171</td>\n",
       "      <td>0.864068</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.839505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859010</td>\n",
       "      <td>0.844171</td>\n",
       "      <td>0.864068</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.839505</td>\n",
       "      <td>0.862337</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.841716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876207</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.839505</td>\n",
       "      <td>0.862337</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.841716</td>\n",
       "      <td>0.868591</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>0.844476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876207</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877975</td>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860819</td>\n",
       "      <td>0.841716</td>\n",
       "      <td>0.868591</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>0.844476</td>\n",
       "      <td>0.867355</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.842903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877975</td>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>0.844476</td>\n",
       "      <td>0.867355</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.842903</td>\n",
       "      <td>0.867084</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.844322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.842903</td>\n",
       "      <td>0.867084</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.866695</td>\n",
       "      <td>0.843710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876158</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.844322</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.866695</td>\n",
       "      <td>0.843710</td>\n",
       "      <td>0.869157</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.866940</td>\n",
       "      <td>0.844475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-120)  var2(t-120)  var3(t-120)  var4(t-120)  var1(t-119)  \\\n",
       "120     0.911499     0.005383     0.909966     0.888220     0.904896   \n",
       "121     0.904896     0.007199     0.906295     0.887362     0.903185   \n",
       "122     0.903185     0.003018     0.904533     0.882607     0.900404   \n",
       "123     0.900404     0.001971     0.900683     0.881134     0.900251   \n",
       "124     0.900251     0.000716     0.900682     0.876073     0.899950   \n",
       "125     0.899950     0.001567     0.899785     0.879122     0.900536   \n",
       "126     0.900536     0.001585     0.899590     0.876207     0.898062   \n",
       "127     0.898062     0.002247     0.899590     0.877975     0.900530   \n",
       "128     0.900530     0.001073     0.899590     0.876218     0.898052   \n",
       "129     0.898052     0.000990     0.899590     0.877294     0.900246   \n",
       "\n",
       "     var2(t-119)  var3(t-119)  var4(t-119)  var1(t-118)  var2(t-118)  \\\n",
       "120     0.007199     0.906295     0.887362     0.903185     0.003018   \n",
       "121     0.003018     0.904533     0.882607     0.900404     0.001971   \n",
       "122     0.001971     0.900683     0.881134     0.900251     0.000716   \n",
       "123     0.000716     0.900682     0.876073     0.899950     0.001567   \n",
       "124     0.001567     0.899785     0.879122     0.900536     0.001585   \n",
       "125     0.001585     0.899590     0.876207     0.898062     0.002247   \n",
       "126     0.002247     0.899590     0.877975     0.900530     0.001073   \n",
       "127     0.001073     0.899590     0.876218     0.898052     0.000990   \n",
       "128     0.000990     0.899590     0.877294     0.900246     0.001661   \n",
       "129     0.001661     0.899590     0.876158     0.900536     0.000313   \n",
       "\n",
       "       ...      var3(t+7)  var4(t+7)  var1(t+8)  var2(t+8)  var3(t+8)  \\\n",
       "120    ...       0.867957   0.846472   0.871304   0.001382   0.869497   \n",
       "121    ...       0.869497   0.846472   0.868639   0.000815   0.869478   \n",
       "122    ...       0.869478   0.846470   0.867833   0.001149   0.869477   \n",
       "123    ...       0.869477   0.845700   0.859604   0.034157   0.859010   \n",
       "124    ...       0.859010   0.844171   0.864068   0.005451   0.859038   \n",
       "125    ...       0.859038   0.839505   0.862337   0.008494   0.860819   \n",
       "126    ...       0.860819   0.841716   0.868591   0.003031   0.864040   \n",
       "127    ...       0.864040   0.844476   0.867355   0.000561   0.865738   \n",
       "128    ...       0.865738   0.842903   0.867084   0.000588   0.865738   \n",
       "129    ...       0.865738   0.844322   0.868439   0.002234   0.866695   \n",
       "\n",
       "     var4(t+8)  var1(t+9)  var2(t+9)  var3(t+9)  var4(t+9)  \n",
       "120   0.846472   0.868639   0.000815   0.869478   0.846470  \n",
       "121   0.846470   0.867833   0.001149   0.869477   0.845700  \n",
       "122   0.845700   0.859604   0.034157   0.859010   0.844171  \n",
       "123   0.844171   0.864068   0.005451   0.859038   0.839505  \n",
       "124   0.839505   0.862337   0.008494   0.860819   0.841716  \n",
       "125   0.841716   0.868591   0.003031   0.864040   0.844476  \n",
       "126   0.844476   0.867355   0.000561   0.865738   0.842903  \n",
       "127   0.842903   0.867084   0.000588   0.865738   0.844322  \n",
       "128   0.844322   0.868439   0.002234   0.866695   0.843710  \n",
       "129   0.843710   0.869157   0.003422   0.866940   0.844475  \n",
       "\n",
       "[10 rows x 520 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_lag, n_out)\n",
    "reframed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-120)</th>\n",
       "      <th>var2(t-120)</th>\n",
       "      <th>var3(t-120)</th>\n",
       "      <th>var4(t-120)</th>\n",
       "      <th>var1(t-119)</th>\n",
       "      <th>var2(t-119)</th>\n",
       "      <th>var3(t-119)</th>\n",
       "      <th>var4(t-119)</th>\n",
       "      <th>var1(t-118)</th>\n",
       "      <th>var2(t-118)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "      <th>var1(t+2)</th>\n",
       "      <th>var1(t+3)</th>\n",
       "      <th>var1(t+4)</th>\n",
       "      <th>var1(t+5)</th>\n",
       "      <th>var1(t+6)</th>\n",
       "      <th>var1(t+7)</th>\n",
       "      <th>var1(t+8)</th>\n",
       "      <th>var1(t+9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.911499</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.909966</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873974</td>\n",
       "      <td>0.867204</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>0.864457</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0.871154</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.868639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867204</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>0.864457</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0.871154</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.867833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>0.864457</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0.871154</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.867833</td>\n",
       "      <td>0.859604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864457</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0.871154</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.867833</td>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.864068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>0.871154</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.868639</td>\n",
       "      <td>0.867833</td>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.864068</td>\n",
       "      <td>0.862337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-120)  var2(t-120)  var3(t-120)  var4(t-120)  var1(t-119)  \\\n",
       "120     0.911499     0.005383     0.909966     0.888220     0.904896   \n",
       "121     0.904896     0.007199     0.906295     0.887362     0.903185   \n",
       "122     0.903185     0.003018     0.904533     0.882607     0.900404   \n",
       "123     0.900404     0.001971     0.900683     0.881134     0.900251   \n",
       "124     0.900251     0.000716     0.900682     0.876073     0.899950   \n",
       "\n",
       "     var2(t-119)  var3(t-119)  var4(t-119)  var1(t-118)  var2(t-118)  \\\n",
       "120     0.007199     0.906295     0.887362     0.903185     0.003018   \n",
       "121     0.003018     0.904533     0.882607     0.900404     0.001971   \n",
       "122     0.001971     0.900683     0.881134     0.900251     0.000716   \n",
       "123     0.000716     0.900682     0.876073     0.899950     0.001567   \n",
       "124     0.001567     0.899785     0.879122     0.900536     0.001585   \n",
       "\n",
       "       ...       var1(t)  var1(t+1)  var1(t+2)  var1(t+3)  var1(t+4)  \\\n",
       "120    ...      0.873974   0.867204   0.868109   0.864457   0.869646   \n",
       "121    ...      0.867204   0.868109   0.864457   0.869646   0.869194   \n",
       "122    ...      0.868109   0.864457   0.869646   0.869194   0.871154   \n",
       "123    ...      0.864457   0.869646   0.869194   0.871154   0.871306   \n",
       "124    ...      0.869646   0.869194   0.871154   0.871306   0.871304   \n",
       "\n",
       "     var1(t+5)  var1(t+6)  var1(t+7)  var1(t+8)  var1(t+9)  \n",
       "120   0.869194   0.871154   0.871306   0.871304   0.868639  \n",
       "121   0.871154   0.871306   0.871304   0.868639   0.867833  \n",
       "122   0.871306   0.871304   0.868639   0.867833   0.859604  \n",
       "123   0.871304   0.868639   0.867833   0.859604   0.864068  \n",
       "124   0.868639   0.867833   0.859604   0.864068   0.862337  \n",
       "\n",
       "[5 rows x 490 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "# We're only concerned with the estimating the close value,\n",
    "# Close should be first in the list of column in the config file\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "for i in range (n_out):\n",
    "    for j in range(1, n_features):\n",
    "        cols_to_drop.append(reframed.shape[1]-(i*n_features+j))\n",
    "\n",
    "reframed.drop(reframed.columns[cols_to_drop], axis=1, inplace=True)\n",
    "\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_values = reframed.values\n",
    "# split into train and test sets\n",
    "training_size = int(0.8* reframed_values.shape[0])\n",
    "train = reframed_values[:training_size, :]\n",
    "test = reframed_values[training_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23562, 120, 4) (23562, 10, 1) (5891, 120, 4) (5891, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "n_obs = n_lag * n_features\n",
    "\n",
    "# We're only concerned with the estimating the close value,\n",
    "# Close should be first in the list of column in the config file\n",
    "\n",
    "n_outputs = n_out * n_features\n",
    "train_x, train_y = train[:, :n_obs], train[:, -n_out:]\n",
    "test_x, test_y = test[:, :n_obs], test[:, -n_out:]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_x = train_x.reshape((train_x.shape[0], n_lag, n_features))\n",
    "test_x = test_x.reshape((test_x.shape[0], n_lag, n_features))\n",
    "\n",
    "# reshape output to be 3D [samples, timesteps, features]\n",
    "train_y = train_y.reshape(-1, n_out, 1)\n",
    "test_y = test_y.reshape(-1, n_out, 1)\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=''.join([CONFIG['folder']['weights'], CONFIG['filename'], '_model', '.json'])\n",
    "model_weights_name=''.join([CONFIG['folder']['weights'], CONFIG['filename'], '_model_weights', '.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 600)               732000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 10, 600)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 300)           1081200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 300)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10, 10)            3010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 10)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 1)             11        \n",
      "=================================================================\n",
      "Total params: 1,816,221\n",
      "Trainable params: 1,816,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM, CuDNNLSTM, GRU,CuDNNGRU\n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "units= CONFIG['lstm_hidden_size']\n",
    "dropout = .6\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units), input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(RepeatVector(n_out))\n",
    "model.add(LSTM(int(units), return_sequences=True))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(units=CONFIG['output_size']))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# We're only concerned with the estimating the close value,\n",
    "# otherwise use n_outputs instead of 1\n",
    "# Dense(n_outputs, ...\n",
    "model.add(TimeDistributed(Dense(1, activation='relu')))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# store model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23562 samples, validate on 5891 samples\n",
      "Epoch 1/50\n",
      "23562/23562 [==============================] - 38s 2ms/step - loss: 0.1140 - val_loss: 0.0445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04447, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 2/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0512 - val_loss: 0.0233\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04447 to 0.02334, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 3/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0410 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02334 to 0.01241, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 4/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0364 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01241 to 0.00995, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 5/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0337 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00995\n",
      "Epoch 6/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0324 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00995\n",
      "Epoch 7/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0303 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00995\n",
      "Epoch 8/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0286 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00995\n",
      "Epoch 9/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0280 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00995 to 0.00835, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 10/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0267 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00835\n",
      "Epoch 11/50\n",
      "23562/23562 [==============================] - 33s 1ms/step - loss: 0.0263 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00835 to 0.00793, saving model to weights/BTC_ETH_lstm_i120_o10_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 12/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00793\n",
      "Epoch 13/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0253 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00793\n",
      "Epoch 14/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0246 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00793\n",
      "Epoch 15/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0254 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00793\n",
      "Epoch 16/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0245 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00793\n",
      "Epoch 17/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0240 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00793\n",
      "Epoch 18/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0235 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00793\n",
      "Epoch 19/50\n",
      "23562/23562 [==============================] - 32s 1ms/step - loss: 0.0232 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00793\n",
      "Epoch 20/50\n",
      "23562/23562 [==============================] - 34s 1ms/step - loss: 0.0295 - val_loss: 0.0244\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00793\n",
      "Epoch 21/50\n",
      "23562/23562 [==============================] - 34s 1ms/step - loss: 0.0307 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00793\n",
      "Epoch 22/50\n",
      "16000/23562 [===================>..........] - ETA: 9s - loss: 0.0252 "
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(test_x, test_y), verbose=1, shuffle=True,\n",
    "                    callbacks=[ModelCheckpoint(model_weights_name, monitor='val_loss', verbose=1,save_best_only='true',\n",
    "                                              save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best weights\n",
    "model.load_weights(model_weights_name)\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction of test data\n",
    "y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_y[:,0]\n",
    "b = y[:,0]\n",
    "c = np.append(b, y[-1], axis=0)\n",
    "\n",
    "# Show how the model fits the test data\n",
    "pyplot.plot(a[:100], label='original')\n",
    "pyplot.plot(b[:100], label='model')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# Show how the model predicts data\n",
    "pos = int(a.shape[0]-n_out*4)\n",
    "pyplot.plot(a[pos:], label='original')\n",
    "pyplot.plot(c[pos:], label='model')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on public data!\n",
    "period = CONFIG['period']\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "# Download a live bitcoin price data set\n",
    "def dl_X(now = None, points = n_lag, period = period, pair=CONFIG['pair']):\n",
    "    if now == None:\n",
    "        now = time.time() \n",
    "    end = now - now % period\n",
    "    #print end, time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(end))\n",
    "    start = end - points*period\n",
    "    #print start, time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(start))\n",
    "    url = \"https://poloniex.com/public?command=returnChartData&currencyPair=%s&start=%d&end=%d&period=%d\" % (pair, start, end, period)\n",
    "    openUrl = urlopen(url)\n",
    "    r = openUrl.read()\n",
    "    openUrl.close()\n",
    "    d = json.loads(r.decode())[-n_lag:]\n",
    "    df = pd.DataFrame(d)\n",
    "    original_columns=[u'close', u'date', u'high', u'low', u'open',u'volume']\n",
    "    new_columns = ['Close','Timestamp','High','Low','Open','Volume']\n",
    "    df = df.loc[:,original_columns]\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(when=None):\n",
    "    rt_df = dl_X(when)\n",
    "    rt_values = rt_df.loc[:,columns].values\n",
    "    rt_scaled = scaler.transform(rt_values)\n",
    "    rt_x = rt_scaled.reshape((1, n_lag, n_features))\n",
    "    print (rt_x.shape)\n",
    "    return rt_scaled, model.predict(rt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some now & past predictions\n",
    "for t in [0, 100, 200, 300, 500, 1000, 2000]:\n",
    "    rt_x, prediction = predict(time.time()-t*period)\n",
    "\n",
    "    current = rt_x[:,0]\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    pyplot.plot(current, label='current')\n",
    "\n",
    "    # shift train predictions for plotting\n",
    "    predictPlot = np.empty_like(current)\n",
    "    predictPlot[:] = np.nan\n",
    "    predictPlot = np.append(predictPlot, prediction)\n",
    "\n",
    "    pyplot.plot(predictPlot, label='prediction')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on live data!\n",
    "starttime=time.time()\n",
    "while True:\n",
    "    now = time.time() \n",
    "    end = now - now % period\n",
    "    print (time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(end)))\n",
    "    rt_x, prediction = predict()\n",
    "\n",
    "    current = rt_x[:,0]\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    pyplot.plot(current, label='current')\n",
    "\n",
    "    # shift train predictions for plotting\n",
    "    predictPlot = np.empty_like(current)\n",
    "    predictPlot[:] = np.nan\n",
    "    predictPlot = np.append(predictPlot, prediction)\n",
    "\n",
    "    pyplot.plot(predictPlot, label='prediction')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    time.sleep(period - ((time.time() - starttime) % period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
